{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "1186d4e9fc71bc68e5c236a61d6a16eabd05ebef8d3df8b6414dc4fb9c6b4b41"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# YOLO で転移学習"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## インポート"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import certifi\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from yolov4.tf import YOLOv4, SaveWeightsCallback\n",
    "import tensorflow as tf"
   ]
  },
  {
   "source": [
    "## 転移学習で使用する学習済みモデルのダウンロード"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロードに失敗しないようにするためのおまじない\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "\n",
    "yolov4_tiny_weights_path = tf.keras.utils.get_file(\n",
    "    fname=\"yolov4-tiny.conv.29\",\n",
    "    origin=\"https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\",\n",
    "    cache_subdir=\"models/yolov4\",\n",
    ")\n",
    "yolov4_tiny_weights_path"
   ]
  },
  {
   "source": [
    "## 学習データを作成\n",
    "\n",
    "labelImg でアノテーションを行い、下記のような構成で保存しておきます。\n",
    "アノテーションの保存書式は YOLO を使用します。\n",
    "\n",
    "```\n",
    "dataset\n",
    "├── classes.txt\n",
    "├── test\n",
    "│  ├── 0001.jpg\n",
    "│  ├── 0001.txt\n",
    "│  ├── 0002.jpg\n",
    "│  ├── 0002.txt\n",
    "│  ├── 0003.jpg\n",
    "│  ├── 0003.txt\n",
    "│  ├── 0004.jpg\n",
    "│  ├── 0004.txt\n",
    "│  ├── 0005.jpg\n",
    "│  └── image_path.txt\n",
    "└── train\n",
    "   ├── 0001.jpg\n",
    "   ├── 0001.txt\n",
    "   ├── 0002.jpg\n",
    "   ├── 0002.txt\n",
    "   ├── 0003.jpg\n",
    "   ├── 0003.txt\n",
    "   ├── 0004.jpg\n",
    "   ├── 0004.txt\n",
    "   ├── 0005.jpg\n",
    "   └── image_path.txt\n",
    "```\n",
    "\n",
    "**classes.txt**\n",
    "\n",
    "アノテーションに対するラベル名を行ごとに定義したファイルです。\n",
    "\n",
    "**サンプル:**\n",
    "\n",
    "```\n",
    "person\n",
    "bicycle\n",
    "car\n",
    "motorbike\n",
    "aeroplane\n",
    "...\n",
    "```\n",
    "\n",
    "**0001.txt, 0002.txt,...**\n",
    "\n",
    "YOLO 形式で保存されたバウンディングボックスの座標です。\n",
    "labelImg でアノテーションを行い、YOLO 形式で保存すれば作成できます。\n",
    ".jpg のファイル名に対応したアノテーションは同名の .txt に保存します。\n",
    "\n",
    "各列の意味は `<label> <x_center> <y_center> <width> <height>` です。\n",
    "\n",
    "- `<label>`: `classes.txt` の何行目のラベル名に対応するかを 0 始まりで指定\n",
    "- `<x_center>`: バウンディングボックスの中心 x 座標を画像の幅で割った値\n",
    "- `<y_center>`: バウンディングボックスの中心 y 座標を画像の高さで割った値\n",
    "- `<width>`: バウンディングボックスの幅を画像の幅で割った値\n",
    "- `<height>`: バウンディングボックスの高さを画像の高さで割った値\n",
    "\n",
    "**サンプル:**\n",
    "```\n",
    "0 0.651231 0.532031 0.132474 0.201563\n",
    "```\n",
    "\n",
    "**image_path.txt**\n",
    "\n",
    "画像データのパスを記述したファイルです。\n",
    "\n",
    "**サンプル:**\n",
    "\n",
    "```\n",
    "0001.jpg\n",
    "0002.jpg\n",
    "0003.jpg\n",
    "0004.jpg\n",
    "0005.jpg\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 学習済みモデルをロード"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLOv4(tiny=True)\n",
    "yolo.classes = \"dataset/classes.txt\"\n",
    "yolo.input_size = 608\n",
    "yolo.batch_size = 5\n",
    "\n",
    "yolo.make_model()\n",
    "yolo.load_weights(yolov4_tiny_weights_path, weights_type=\"yolo\")"
   ]
  },
  {
   "source": [
    "## 学習データと検証データをロード\n",
    "\n",
    "`image_path.txt` 内の画像データのパスは `image_path_prefix` からの相対パスとみなされます。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = yolo.load_dataset(\n",
    "    \"dataset/train/image_path.txt\",\n",
    "    dataset_type=\"yolo\",\n",
    "    image_path_prefix=\"dataset/train\",\n",
    "    label_smoothing=0.05,\n",
    "    training=True,\n",
    ")\n",
    "validation_data = yolo.load_dataset(\n",
    "    \"dataset/test/image_path.txt\",\n",
    "    dataset_type=\"yolo\",\n",
    "    image_path_prefix=\"dataset/test\",\n",
    "    training=False,\n",
    ")"
   ]
  },
  {
   "source": [
    "## ハイパーパラメータを定義"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "yolo.compile(optimizer=optimizer, loss_iou_type=\"ciou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learning_rate_scheduler(epochs):\n",
    "    def scheduler(epoch, lr):\n",
    "        if epoch < int(epochs * 0.5):\n",
    "            return lr\n",
    "        elif epoch < int(epochs * 0.8):\n",
    "            return lr * 0.5\n",
    "        elif epoch < int(epochs * 0.9):\n",
    "            return lr * 0.1\n",
    "        else:\n",
    "            return lr * 0.01\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "source": [
    "## 学習を開始"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=5,\n",
    "    validation_freq=10,\n",
    "    steps_per_epoch=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.LearningRateScheduler(create_learning_rate_scheduler(epochs)),\n",
    "        tf.keras.callbacks.TerminateOnNaN(),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=\"logs\"),\n",
    "        SaveWeightsCallback(\n",
    "            yolo=yolo,\n",
    "            dir_path=\"weights\",\n",
    "            weights_type=\"yolo\",\n",
    "            epoch_per_save=10,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "source": [
    "## 学習したモデルを使用"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.load_weights(\"weights/yolov4-tiny-final.weights\", weights_type=\"yolo\")\n",
    "\n",
    "with open(\"dataset/test/image_path.txt\") as f:\n",
    "    output_images = []\n",
    "\n",
    "    for image_path in map(lambda x: f\"dataset/test/{x.strip()}\", f):\n",
    "        print(image_path)\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = np.array(image)\n",
    "\n",
    "        boxes = yolo.predict(image)\n",
    "        output_image = yolo.draw_bboxes(image, boxes)\n",
    "        output_image = Image.fromarray(output_image)\n",
    "\n",
    "        output_images.append(output_image)\n",
    "\n",
    "    output_images[0].save(\"out.gif\", save_all=True, append_images=output_images[1:], loop=0)"
   ]
  }
 ]
}